{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    'window_size': 2,\n",
    "    'n': 10,\n",
    "    'epochs': 50,\n",
    "    'learning_rate': 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class word2vec():\n",
    "    #иницилизация гиперпараметров, а также текста и размера матриц, который зависит от текста\n",
    "    def __init__(self):\n",
    "        self.n = settings['n']\n",
    "        self.lr = settings['learning_rate']\n",
    "        self.epochs = settings['epochs']\n",
    "        self.window = settings['window_size']\n",
    "        self.your_text = your_text\n",
    "        self.output_size = len(your_text.split())\n",
    "        self.input_size = len(your_text.split()) + 1\n",
    "        self.getW1 = np.array([[np.random.normal(loc=0, scale=0.01) for i in range(self.input_size)]\n",
    "                               for x in range(self.output_size)])\n",
    "        self.getW2 = np.array([[np.random.normal(loc=0, scale=0.01) for i in range(self.output_size)]\n",
    "                               for x in range(self.input_size)])\n",
    "        \n",
    "    #генерируем тренировочную дату\n",
    "    def generate_training_data(self, settings, corpus):        \n",
    "        word_counts = defaultdict(int)\n",
    "        for row in corpus:\n",
    "            for word in row:\n",
    "                word_counts[word] += 1\n",
    "                \n",
    "        self.v_count = len(word_counts.keys())\n",
    "                           \n",
    "        self.words_list = list(word_counts.keys())\n",
    "                           \n",
    "        self.word_index = dict((word, i) for i, word in enumerate(self.words_list))\n",
    "                           \n",
    "        self.index_word = dict((i, word) for i, word in enumerate(self.words_list))\n",
    "                           \n",
    "        training_data = []\n",
    "        \n",
    "        corpus = [[word.lower() for word in self.your_text.split()]]\n",
    "        \n",
    "        for sentence in corpus:\n",
    "            sent_len = len(sentence)\n",
    "            \n",
    "            for i, word in enumerate(sentence):\n",
    "                w_target = self.word2onehot(sentence[i])\n",
    "\n",
    "                w_context = []  \n",
    "                \n",
    "                for j in range(i - self.window, i + self.window+1):\n",
    "                    if j != i and j <= sent_len-1 and j >= 0:\n",
    "                        w_context.append(self.word2onehot(sentence[j]))\n",
    "                training_data.append([w_target, w_context])\n",
    "        return np.array(training_data)\n",
    "      \n",
    "                           \n",
    "    def word2onehot(self, word):\n",
    "        word_vec = [0 for i in range(0, self.v_count)]\n",
    "        word_index = self.word_index[word]\n",
    "        word_vec[word_index] = 1\n",
    "        return word_vec\n",
    "                           \n",
    "    def train(self, training_data):\n",
    "        self.w1 = np.array(self.getW1)\n",
    "        self.w2 = np.array(self.getW2)\n",
    "                           \n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            self.loss = 0\n",
    "            for w_t, w_c in training_data:\n",
    "                y_pred, h, u = self.forward_pass(w_t)\n",
    "                EI = np.sum([np.subtract(y_pred, word) for word in w_c], axis=0)\n",
    "                           \n",
    "                self.backprop(EI, h, w_t)\n",
    "                \n",
    "                self.loss += -np.sum([u[word.index(1)] for word in w_c]) + len(w_c)\n",
    "                           \n",
    "            print('Epoch:', i, \"Loss:\", self.loss)\n",
    "            \n",
    "    def forward_pass(self, x):\n",
    "        h = np.dot(x, self.w1)\n",
    "        u = np.dot(h, self.w2)\n",
    "        y_c = self.softmax(u)\n",
    "        return y_c, h, u\n",
    "        \n",
    "    def softmax(self, x):\n",
    "        e_x = np.exp(x - np.max(x))\n",
    "        return e_x / e_x.sum(axis=0)\n",
    "                           \n",
    "    def backprop(self, e, h, x):\n",
    "        dl_dw2 = np.outer(h, e)\n",
    "        dl_dw1 = np.outer(x, np.dot(self.w2, e.T))\n",
    "                           \n",
    "        self.w1 = self.w1 - (self.lr * dl_dw1)\n",
    "        self.w2 = self.w2 - (self.lr * dl_dw2)\n",
    "                           \n",
    "    def word_vec(self, word):\n",
    "        w_index = self.word_index[word]\n",
    "        v_w = self.w1[w_index]\n",
    "        return v_w\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_text = 'one two free' #наш текст\n",
    "def train(your_text): #функция для возвращения словаря\n",
    "    w2v = word2vec()\n",
    "    corpus = [[word.lower() for word in your_text.split()]]\n",
    "    training_data = w2v.generate_training_data(settings, corpus)\n",
    "    w2v.train(training_data)\n",
    "    w2v_dict = {word: w2v.word_vec(word) for word in your_text.split()} #создаём словарь\n",
    "    return w2v_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 5.999238985756092\n",
      "Epoch: 1 Loss: 5.999232035150097\n",
      "Epoch: 2 Loss: 5.99922497457178\n",
      "Epoch: 3 Loss: 5.999217801214104\n",
      "Epoch: 4 Loss: 5.9992105122255115\n",
      "Epoch: 5 Loss: 5.99920310470878\n",
      "Epoch: 6 Loss: 5.9991955757198845\n",
      "Epoch: 7 Loss: 5.999187922266826\n",
      "Epoch: 8 Loss: 5.999180141308451\n",
      "Epoch: 9 Loss: 5.999172229753244\n",
      "Epoch: 10 Loss: 5.999164184458104\n",
      "Epoch: 11 Loss: 5.999156002227105\n",
      "Epoch: 12 Loss: 5.999147679810226\n",
      "Epoch: 13 Loss: 5.9991392139020645\n",
      "Epoch: 14 Loss: 5.999130601140537\n",
      "Epoch: 15 Loss: 5.999121838105539\n",
      "Epoch: 16 Loss: 5.999112921317598\n",
      "Epoch: 17 Loss: 5.999103847236496\n",
      "Epoch: 18 Loss: 5.999094612259868\n",
      "Epoch: 19 Loss: 5.999085212721781\n",
      "Epoch: 20 Loss: 5.999075644891283\n",
      "Epoch: 21 Loss: 5.9990659049709265\n",
      "Epoch: 22 Loss: 5.9990559890952735\n",
      "Epoch: 23 Loss: 5.999045893329359\n",
      "Epoch: 24 Loss: 5.999035613667143\n",
      "Epoch: 25 Loss: 5.999025146029928\n",
      "Epoch: 26 Loss: 5.999014486264743\n",
      "Epoch: 27 Loss: 5.999003630142708\n",
      "Epoch: 28 Loss: 5.998992573357359\n",
      "Epoch: 29 Loss: 5.9989813115229556\n",
      "Epoch: 30 Loss: 5.998969840172739\n",
      "Epoch: 31 Loss: 5.9989581547571795\n",
      "Epoch: 32 Loss: 5.99894625064217\n",
      "Epoch: 33 Loss: 5.998934123107208\n",
      "Epoch: 34 Loss: 5.998921767343525\n",
      "Epoch: 35 Loss: 5.998909178452191\n",
      "Epoch: 36 Loss: 5.998896351442187\n",
      "Epoch: 37 Loss: 5.998883281228428\n",
      "Epoch: 38 Loss: 5.998869962629765\n",
      "Epoch: 39 Loss: 5.998856390366938\n",
      "Epoch: 40 Loss: 5.998842559060497\n",
      "Epoch: 41 Loss: 5.998828463228682\n",
      "Epoch: 42 Loss: 5.998814097285257\n",
      "Epoch: 43 Loss: 5.9987994555373145\n",
      "Epoch: 44 Loss: 5.998784532183035\n",
      "Epoch: 45 Loss: 5.998769321309393\n",
      "Epoch: 46 Loss: 5.998753816889831\n",
      "Epoch: 47 Loss: 5.998738012781895\n",
      "Epoch: 48 Loss: 5.998721902724801\n",
      "Epoch: 49 Loss: 5.998705480336984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'one': array([ 0.01200067,  0.00646814, -0.00113942,  0.00237128]),\n",
       " 'two': array([-0.00333234,  0.00654017, -0.01049422,  0.01786332]),\n",
       " 'free': array([-0.01690989, -0.00951925, -0.01364383,  0.00172942])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(your_text) #пример1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 13.99930315898227\n",
      "Epoch: 1 Loss: 13.999249838134842\n",
      "Epoch: 2 Loss: 13.999196126860456\n",
      "Epoch: 3 Loss: 13.999141982889308\n",
      "Epoch: 4 Loss: 13.999087363450775\n",
      "Epoch: 5 Loss: 13.999032225231431\n",
      "Epoch: 6 Loss: 13.998976524332509\n",
      "Epoch: 7 Loss: 13.998920216226733\n",
      "Epoch: 8 Loss: 13.998863255714522\n",
      "Epoch: 9 Loss: 13.998805596879505\n",
      "Epoch: 10 Loss: 13.998747193043279\n",
      "Epoch: 11 Loss: 13.998687996719411\n",
      "Epoch: 12 Loss: 13.998627959566587\n",
      "Epoch: 13 Loss: 13.998567032340894\n",
      "Epoch: 14 Loss: 13.998505164847195\n",
      "Epoch: 15 Loss: 13.9984423058895\n",
      "Epoch: 16 Loss: 13.998378403220329\n",
      "Epoch: 17 Loss: 13.998313403489018\n",
      "Epoch: 18 Loss: 13.99824725218887\n",
      "Epoch: 19 Loss: 13.99817989360315\n",
      "Epoch: 20 Loss: 13.998111270749828\n",
      "Epoch: 21 Loss: 13.998041325325062\n",
      "Epoch: 22 Loss: 13.997969997645308\n",
      "Epoch: 23 Loss: 13.997897226588046\n",
      "Epoch: 24 Loss: 13.997822949531031\n",
      "Epoch: 25 Loss: 13.997747102290043\n",
      "Epoch: 26 Loss: 13.997669619055028\n",
      "Epoch: 27 Loss: 13.997590432324618\n",
      "Epoch: 28 Loss: 13.997509472838905\n",
      "Epoch: 29 Loss: 13.99742666951048\n",
      "Epoch: 30 Loss: 13.997341949353572\n",
      "Epoch: 31 Loss: 13.997255237411332\n",
      "Epoch: 32 Loss: 13.997166456681054\n",
      "Epoch: 33 Loss: 13.997075528037396\n",
      "Epoch: 34 Loss: 13.996982370153436\n",
      "Epoch: 35 Loss: 13.9968868994195\n",
      "Epoch: 36 Loss: 13.99678902985971\n",
      "Epoch: 37 Loss: 13.996688673046155\n",
      "Epoch: 38 Loss: 13.996585738010573\n",
      "Epoch: 39 Loss: 13.996480131153522\n",
      "Epoch: 40 Loss: 13.996371756150877\n",
      "Epoch: 41 Loss: 13.996260513857623\n",
      "Epoch: 42 Loss: 13.996146302208796\n",
      "Epoch: 43 Loss: 13.996029016117554\n",
      "Epoch: 44 Loss: 13.995908547370156\n",
      "Epoch: 45 Loss: 13.995784784517896\n",
      "Epoch: 46 Loss: 13.995657612765752\n",
      "Epoch: 47 Loss: 13.99552691385774\n",
      "Epoch: 48 Loss: 13.995392565958813\n",
      "Epoch: 49 Loss: 13.99525444353319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'one': array([ 0.00550657,  0.00587883,  0.0065588 , -0.01594234, -0.02094437,\n",
       "        -0.01457493]),\n",
       " 'two': array([ 0.01289824, -0.01709041,  0.01038659, -0.00306691,  0.02860904,\n",
       "         0.00128626]),\n",
       " 'free': array([ 0.00376701, -0.00985002,  0.01274947, -0.00328491, -0.00874226,\n",
       "        -0.00328365]),\n",
       " 'four': array([-0.02284178,  0.01747276,  0.00507223,  0.00632609, -0.02170538,\n",
       "         0.00569176]),\n",
       " 'five': array([-0.00652117, -0.00286432, -0.00620127,  0.01358764, -0.00085349,\n",
       "         0.00171116])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "your_text = 'one two free four five'\n",
    "train(your_text) #пример 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 17.999083488915865\n",
      "Epoch: 1 Loss: 17.998945584038708\n",
      "Epoch: 2 Loss: 17.998806590007636\n",
      "Epoch: 3 Loss: 17.99866636922765\n",
      "Epoch: 4 Loss: 17.998524782908664\n",
      "Epoch: 5 Loss: 17.9983816909126\n",
      "Epoch: 6 Loss: 17.998236951599047\n",
      "Epoch: 7 Loss: 17.998090421669403\n",
      "Epoch: 8 Loss: 17.997941956009225\n",
      "Epoch: 9 Loss: 17.99779140752867\n",
      "Epoch: 10 Loss: 17.99763862700085\n",
      "Epoch: 11 Loss: 17.997483462897872\n",
      "Epoch: 12 Loss: 17.99732576122441\n",
      "Epoch: 13 Loss: 17.997165365348657\n",
      "Epoch: 14 Loss: 17.99700211583037\n",
      "Epoch: 15 Loss: 17.99683585024593\n",
      "Epoch: 16 Loss: 17.99666640301013\n",
      "Epoch: 17 Loss: 17.99649360519457\n",
      "Epoch: 18 Loss: 17.996317284342354\n",
      "Epoch: 19 Loss: 17.99613726427903\n",
      "Epoch: 20 Loss: 17.995953364919412\n",
      "Epoch: 21 Loss: 17.995765402070163\n",
      "Epoch: 22 Loss: 17.995573187227915\n",
      "Epoch: 23 Loss: 17.99537652737266\n",
      "Epoch: 24 Loss: 17.995175224756217\n",
      "Epoch: 25 Loss: 17.99496907668556\n",
      "Epoch: 26 Loss: 17.994757875300714\n",
      "Epoch: 27 Loss: 17.994541407347036\n",
      "Epoch: 28 Loss: 17.99431945394159\n",
      "Epoch: 29 Loss: 17.994091790333403\n",
      "Epoch: 30 Loss: 17.9938581856573\n",
      "Epoch: 31 Loss: 17.99361840268106\n",
      "Epoch: 32 Loss: 17.993372197545696\n",
      "Epoch: 33 Loss: 17.993119319498415\n",
      "Epoch: 34 Loss: 17.992859510618167\n",
      "Epoch: 35 Loss: 17.992592505533352\n",
      "Epoch: 36 Loss: 17.99231803113143\n",
      "Epoch: 37 Loss: 17.99203580626012\n",
      "Epoch: 38 Loss: 17.991745541419917\n",
      "Epoch: 39 Loss: 17.991446938447528\n",
      "Epoch: 40 Loss: 17.991139690189893\n",
      "Epoch: 41 Loss: 17.99082348016859\n",
      "Epoch: 42 Loss: 17.99049798223407\n",
      "Epoch: 43 Loss: 17.990162860209516\n",
      "Epoch: 44 Loss: 17.98981776752389\n",
      "Epoch: 45 Loss: 17.989462346833808\n",
      "Epoch: 46 Loss: 17.98909622963385\n",
      "Epoch: 47 Loss: 17.988719035854945\n",
      "Epoch: 48 Loss: 17.988330373450296\n",
      "Epoch: 49 Loss: 17.987929837968654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'one': array([ 0.0004641 ,  0.0114827 ,  0.01128569, -0.01921965,  0.01070365,\n",
       "        -0.01269281,  0.00998191]),\n",
       " 'two': array([ 0.00847985, -0.03666456, -0.01834598, -0.00728984,  0.01102393,\n",
       "         0.01159885,  0.00655206]),\n",
       " 'free': array([ 0.0090774 , -0.00022874, -0.0002884 , -0.01166282,  0.01693539,\n",
       "        -0.00220819, -0.00258049]),\n",
       " 'four': array([-0.01992802,  0.03628376,  0.03707087, -0.00669192, -0.00273951,\n",
       "        -0.00586849,  0.00305702]),\n",
       " 'five': array([ 0.01718522, -0.00797481,  0.00859062, -0.00890876, -0.00921552,\n",
       "         0.02401479, -0.0046938 ]),\n",
       " 'six': array([ 0.00414751, -0.02942722,  0.00739562,  0.0001866 , -0.00153738,\n",
       "         0.01957432,  0.01100757])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "your_text = 'one two free four five six'\n",
    "train(your_text) #пример 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 1.9996057562251783\n",
      "Epoch: 1 Loss: 1.999598035621276\n",
      "Epoch: 2 Loss: 1.9995901986522846\n",
      "Epoch: 3 Loss: 1.9995822422016172\n",
      "Epoch: 4 Loss: 1.9995741631054753\n",
      "Epoch: 5 Loss: 1.9995659581515968\n",
      "Epoch: 6 Loss: 1.9995576240779802\n",
      "Epoch: 7 Loss: 1.9995491575715947\n",
      "Epoch: 8 Loss: 1.999540555267066\n",
      "Epoch: 9 Loss: 1.9995318137453437\n",
      "Epoch: 10 Loss: 1.9995229295323482\n",
      "Epoch: 11 Loss: 1.9995138990975936\n",
      "Epoch: 12 Loss: 1.9995047188527906\n",
      "Epoch: 13 Loss: 1.9994953851504267\n",
      "Epoch: 14 Loss: 1.9994858942823213\n",
      "Epoch: 15 Loss: 1.9994762424781594\n",
      "Epoch: 16 Loss: 1.999466425904\n",
      "Epoch: 17 Loss: 1.9994564406607576\n",
      "Epoch: 18 Loss: 1.999446282782662\n",
      "Epoch: 19 Loss: 1.9994359482356896\n",
      "Epoch: 20 Loss: 1.999425432915967\n",
      "Epoch: 21 Loss: 1.9994147326481508\n",
      "Epoch: 22 Loss: 1.9994038431837744\n",
      "Epoch: 23 Loss: 1.9993927601995716\n",
      "Epoch: 24 Loss: 1.9993814792957674\n",
      "Epoch: 25 Loss: 1.9993699959943383\n",
      "Epoch: 26 Loss: 1.9993583057372455\n",
      "Epoch: 27 Loss: 1.9993464038846338\n",
      "Epoch: 28 Loss: 1.9993342857129992\n",
      "Epoch: 29 Loss: 1.9993219464133247\n",
      "Epoch: 30 Loss: 1.9993093810891809\n",
      "Epoch: 31 Loss: 1.9992965847547945\n",
      "Epoch: 32 Loss: 1.9992835523330803\n",
      "Epoch: 33 Loss: 1.999270278653639\n",
      "Epoch: 34 Loss: 1.999256758450716\n",
      "Epoch: 35 Loss: 1.9992429863611259\n",
      "Epoch: 36 Loss: 1.9992289569221375\n",
      "Epoch: 37 Loss: 1.99921466456932\n",
      "Epoch: 38 Loss: 1.9992001036343496\n",
      "Epoch: 39 Loss: 1.9991852683427758\n",
      "Epoch: 40 Loss: 1.9991701528117451\n",
      "Epoch: 41 Loss: 1.9991547510476857\n",
      "Epoch: 42 Loss: 1.9991390569439447\n",
      "Epoch: 43 Loss: 1.9991230642783837\n",
      "Epoch: 44 Loss: 1.9991067667109306\n",
      "Epoch: 45 Loss: 1.9990901577810822\n",
      "Epoch: 46 Loss: 1.9990732309053625\n",
      "Epoch: 47 Loss: 1.9990559793747327\n",
      "Epoch: 48 Loss: 1.9990383963519505\n",
      "Epoch: 49 Loss: 1.9990204748688836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hey': array([0.00856688, 0.02418843, 0.01080571]),\n",
       " 'guys': array([ 0.02058638, -0.01435757,  0.00654123])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "your_text = 'hey guys'\n",
    "train(your_text) #пример 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
